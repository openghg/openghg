{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner workflow\n",
    "\n",
    "This tutorial is a beginner workflow for processing data, visualising the object store and retrieving and visualising data.\n",
    "\n",
    "### Check installation\n",
    "\n",
    "This tutorial assumes that you have installed `openghg`. To ensure install has been successful you can open an `ipython` console and import openghg\n",
    "\n",
    "In a terminal type\n",
    "\n",
    "```bash\n",
    "ipython\n",
    "```\n",
    "\n",
    "Then import `openghg` and print the version string associated with the version you have installed. If you get something like the below `openghg` is installed correctly.\n",
    "\n",
    "```ipython\n",
    "In [1]: import openghg\n",
    "In [2]: openghg.__version__\n",
    "Out[2]: '0.0.1'\n",
    "```\n",
    "\n",
    "If you get an ``ImportError`` please go back to the install section of the documentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "If you haven't used Jupyter notebooks before please see [this introduction](https://realpython.com/jupyter-notebook-introduction/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up our environment\n",
    "\n",
    "First the notebook sets up the environment needed to create the object store at our desired location. By default this location\n",
    "is at ``/tmp/openghg_store``. For the purposes of this tutorial this path is fine but as it is a temporary directory it may not survive a\n",
    "reboot of the computer. \n",
    "\n",
    "If you want to create an object store that survives a reboot you can change the path to anything you like. We\n",
    "recommened a path such as ``~/openghg_store`` which will create the object store in your home directory in a directory called ``openghg_store``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openghg.store import ObsSurface\n",
    "from openghg.objectstore import visualise_store\n",
    "from openghg.localclient import get_obs_surface, RankSources\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set an environment variable for the OpenGHG object store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a temporary directory but you can use any folder you like by setting a path in place of `tmp_dir.name`. The object store created by this notebook will only have a lifetime as long as the notebook, if you want to create a longer lived object store set a path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "os.environ[\"OPENGHG_PATH\"] = tmp_dir.name # \"/tmp/openghg_store\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to process some files from our local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decc_file = \"../data/DECC/bsd.picarro.1minute.248m.min.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass this filepath to `ObsSurface.read_file`. We must also tell it the type of data we want it to process, DECC data is CRDS. We also pass in the site code and the name of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decc_results = ObsSurface.read_file(filepath=decc_file, data_type=\"CRDS\", site=\"bsd\", network=\"DECC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `decc_results` will give us a dictionary with the UUIDs (universally unique identifiers) for each of the Datasources the data has been assigned to. This tells us that the data has been processed and stored correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on Datasources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasources are objects that are stored in the object store (add link to object store notes) that hold the data and metadata associated with each measurement we upload to the platform.\n",
    "\n",
    "For example, if we upload a file that contains readings for three gas species from a single site at a specific inlet height OpenGHG    will assign this data to three different Datasources, one for each species. Metadata such as the site, inlet height, species, network etc are stored alongside the measurements for easy searching. \n",
    "\n",
    "Datasources can also handle multiple versions of data from a single site, so if scales or other factors change multiple versions may be stored for easy future comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "When you run this notebook different UUIDs will be created for the Datasources. This is expected as \n",
    "each time a Datasource is created from scratch it is assigned a unique UUID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now process the AGAGE data. The functions that process the AGAGE data expect data to have an accompanying precisions file. For each data file we create a tuple with the data filename and the precisions filename. A simpler method of uploading these file types is planned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must create a `tuple` for each pair\n",
    "\n",
    "```python\n",
    "list_of_tuples = [(data_filepath, precision_filepath), (d1, p1), (d2, p2), ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agage_tuples = [('../data/AGAGE/capegrim-medusa.18.C', '../data/AGAGE/capegrim-medusa.18.precisions.C')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we process the files as we did before the with DECC data, but this time changing the data type to the `GCWERKS` type and the network to `AGAGE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agage_results = ObsSurface.read_file(filepath=agage_tuples, data_type=\"GCWERKS\", site=\"CGO\", network=\"AGAGE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When viewing `agage_results` there will be a large number of Datasource UUIDs shown due to the large number of gases in each data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agage_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualising the object store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a simple object store created we can view the objects within it in a simple force graph model. To do this we use the `view_store` function from the `objectstore` submodule. Note that the cell may take a few moments to load as the force graph is created.\n",
    "\n",
    "In the force graph the central blue node is the `ObsSurface` node. Associated with this node are all the data processed by it. The next node in the topology are networks, shown in green. In the graph you will see `DECC` and `AGAGE` nodes. From these you'll see site nodes in red and then individual datasources in orange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "The object store visualisation created by this function is commented out here and won't be visible in the documentation but can be uncommented and run when you use the notebook version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know we have this data in the object store we can search it and retrieve data from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retrieving data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve data from the object store we can use the `get_obs_surface` function from the `localclient` submodule. This allows us to retrieve and view the data stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_obs_surface(site=\"bsd\", species=\"co\", network=\"AGAGE\", inlet=\"248m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we view data we expect an `ObsData` object to have been returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we tell `matplotlib` that we are plotting inside a Jupyter notebook, this ensures a plot with controls is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = data.data\n",
    "mol_frac = example_data.mf\n",
    "mol_frac.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ranking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dates that the data from Heathfield retrieved above overlap. If we want to easily retrieve the highest quality data from Heathfield over a range of dates we don't want to have to repeatedly check which was the correct inlet/instrument for a given daterange. This problem is solved using ranking. \n",
    "\n",
    "A given inlet on a specific instrument at a site can be given a rank for a daterange. To do this we use the `RankSources` class from the `localclient` submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rest of tutorial requires updating, the cells below will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = RankSources()\n",
    "\n",
    "#r.get_sources(site=\"hfd\", species=\"co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dictionary gives us two keys, one for each inlet height. To rank a source we use the `set_rank` method which expects two arguments: `rank_key` which is the key given to each source in the `dict` above and `rank_data` a dictionary of the form\n",
    "\n",
    "```python\n",
    "rank_data = {co2_hfd_50m_picarro: {1: [daterange_1], 2: [daterange_2]}}\n",
    "```\n",
    "\n",
    "We can create this dictionary using a helper method of `RankSources` called `create_daterange` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daterange_100m = r.create_daterange(start=\"2013-11-01\", end=\"2016-01-01\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a daterange string that will be understood by `openghg`. We can then place this in a list to create our `rank_data` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank_data = {\"co_hfd_100m_picarro\": {\"1\": [daterange_100m]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set the rank of the network using `set_rank`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.set_rank(rank_key=\"co_hfd_100m_picarro\", rank_data=rank_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check the rank for this inlet again to check it's been set correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.get_sources(site=\"hfd\", species=\"co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see\n",
    "\n",
    "```python\n",
    "'co_hfd_100m_picarro': {'rank': defaultdict(list, {'1': ['2013-11-01T00:00:00_2016-01-01T00:00:00']})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which tells us the rank was set correctly over the daterange that we specified. We can now search for data and we'll automatically get the highest ranked data.\n",
    "\n",
    "Let's search for CO2 data at Heathfield between 2014 - 2015, dates covered by both inlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_data = get_obs_surface(site=\"hfd\", species=\"co\", network=\"AGAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the highest ranked data returned to us without the need to specify an inlet height or instrument.\n",
    "\n",
    "If we know that we want data from the 50m inlet we can still specify this in the search and get that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fiftym_data = get_obs_surface(site=\"hfd\", species=\"co\", network=\"AGAGE\", inlet=\"50m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fiftym_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Viewing ranked data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the ranks we have given to data with a similar layout to the object store visualisation we created earlier.\n",
    "\n",
    "To do this we use the `visualise_rankings` method of of the `RankSources` class. In this figure we'll only see Datasources that contain ranked data. Hover over the nodes for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "The rankings visualisation created by this function is commented out here and won't be visible in the documentation but can be uncommented and run when you use the notebook version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.visualise_rankings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used the `tmp_dir` as a location for your object store at the start of the tutorial you can run the cell below to remove any files that were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further tutorials will be added soon. If you want to explore the internal workings of OpenGHG please checkout the Developer API documentation, if you would like contribute to the project we welcome pull requests to both the code and the documentation. For help and guidance on contributing check our contributing page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
